{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Librerie caricate!\n"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "import json\n",
    "from itertools import islice\n",
    "import os\n",
    "import time\n",
    "import pprint\n",
    "import requests\n",
    "import random\n",
    "import networkx as nx\n",
    "from networkx.algorithms.approximation import clique\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "from pyvis.network import Network\n",
    "import itertools \n",
    "\n",
    "print(\"Librerie caricate!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pp=pprint.PrettyPrinter()\n",
    "\n",
    "def serialize_json(folder, filename, data):\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder, exist_ok=True)\n",
    "    with open(f\"{folder}/{filename}\", 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "        f.close()\n",
    "    print(f\"Data serialized to path: {folder}/{filename}\")\n",
    "\n",
    "def read_json(path):\n",
    "    if os.path.exists(path):\n",
    "        with open(path, \"r\", encoding=\"utf8\") as file:\n",
    "            data = json.load(file)\n",
    "        print(f\"Data read from path: {path}\")\n",
    "        return data\n",
    "    else:\n",
    "        print(f\"No data found at path: {path}\")\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key=\"cvoM8D7hXXxlvBXTM8aH9X2ec\"\n",
    "api_secret=\"Uk2UvH0FJY7KaDzkXYLfgiYkA1OuCwbLlGFPyodB5wcQ5bsItN\"\n",
    "\n",
    "access_token=\"3303466053-OLuExo5KcP8UQCVwZwmyakZs8b91Fpl2lMOUDAe\"\n",
    "access_secret=\"1lMXufu42KN8JvJjYT7c0zI3Q57CkN09BxkNXZuNQ0Dej\"\n",
    "\n",
    "bearer_token=\"AAAAAAAAAAAAAAAAAAAAAHsVJQEAAAAAQ4vYb83r6ueD8QvjJ4Zpx9R7Kbw%3DQuLzsmDYOvpff7lRHGXhNJSOXTFuPyOwLHZv7HPSj9WF34h1E8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auth success\n"
     ]
    }
   ],
   "source": [
    "auth=tweepy.OAuthHandler(api_key,api_secret)\n",
    "auth.set_access_token(access_token,access_secret)\n",
    "api=tweepy.API(auth,wait_on_rate_limit=True,wait_on_rate_limit_notify=True)\n",
    "if(api.verify_credentials):\n",
    "    print(\"Auth success\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "users=[\"mizzaro\",\"damiano10\",\"miccighel_\",\"eglu81\",\"KevinRoitero\"]\n",
    "users_id=[18932422, 132646210, 15750573, 19659370, 3036907250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'users_id' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-92d9685eb7ed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mfollowers_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfollowing_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mutente\u001b[0m \u001b[1;32min\u001b[0m \u001b[0musers_id\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mfollowers_utente\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfollowing_utente\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     for item in tweepy.Cursor(\n",
      "\u001b[1;31mNameError\u001b[0m: name 'users_id' is not defined"
     ]
    }
   ],
   "source": [
    "#1. Scaricate\n",
    "#codice da non eseguire a meno che non vogliate bruciarvi tutte le richieste di twitter API\n",
    "followers_ids,following_ids={},{}\n",
    "\n",
    "for utente in users_id:\n",
    "    followers_utente,following_utente=[],[]\n",
    "    for item in tweepy.Cursor(\n",
    "        api.followers,\n",
    "        id=utente,\n",
    "        skip_status=True,\n",
    "        include_user_entities=False\n",
    "    ).items():\n",
    "        json_data=item._json\n",
    "        user={\"id\":json_data[\"id\"]}\n",
    "        time.sleep(181)\n",
    "        #followers_utente.append({id:item._data[\"id\"]})\n",
    "        followers_utente.append(user)\n",
    "\n",
    "    followers_ids[utente]=followers_utente\n",
    "\n",
    "    for item in tweepy.Cursor(\n",
    "        api.friends,\n",
    "        id=utente,\n",
    "        skip_status=True,\n",
    "        include_user_entities=False\n",
    "    ).items():\n",
    "        json_data=item._json\n",
    "        user={\"id\":json_data[\"id\"]}\n",
    "        time.sleep(181)\n",
    "        following_utente.append(user)\n",
    "\n",
    "    following_ids[utente]=following_utente\n",
    "\n",
    "#followers_ids={\"mizzaro\":[123,456,789,...],\"damiano10\":[123,789,367,...],...}\n",
    "#export to json\n",
    "serialize_json(\"data\",\"followers_principali.json\",followers_ids)\n",
    "serialize_json(\"data\",\"following_principali.json\",following_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data read from path: json_5_utenti/finale/followers.json\n",
      "Data read from path: json_5_utenti/finale/following.json\n"
     ]
    }
   ],
   "source": [
    "followers_ids=read_json(\"data_ids/finale/followers.json\")\n",
    "following_ids=read_json(\"data_ids/finale/following.json\")\n",
    "#Temporaneamente ho unito i followers/ing di ogni utente in due file separati, non so se Ã¨ giusto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Sample larger than population or is negative",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-2aa6c392e4d3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mutente\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfollowers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrandom_followers_utenti\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mutente\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mfollowers_of_followers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mutente\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_followers_utenti\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mutente\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.8_3.8.1776.0_x64__qbz5n2kfra8p0\\lib\\random.py\u001b[0m in \u001b[0;36msample\u001b[1;34m(self, population, k)\u001b[0m\n\u001b[0;32m    361\u001b[0m         \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mk\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 363\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Sample larger than population or is negative\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m         \u001b[0msetsize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m21\u001b[0m        \u001b[1;31m# size of a small set minus size of an empty list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Sample larger than population or is negative"
     ]
    }
   ],
   "source": [
    "followers_ids, following_ids = [], []\n",
    "\n",
    "# punto 2&3\n",
    "followers_ids = read_json(\"/followers_5_utenti.json\")\n",
    "following_ids = read_json(\"/following_5_utenti.json\")\n",
    "\n",
    "# 2\n",
    "random_followers_utenti_ids, followers_of_followers_ids = {}, {}\n",
    "\n",
    "for utente in followers_ids:\n",
    "    random_followers_utenti_ids[utente] = random.sample(followers_ids[utente], 5)\n",
    "# result: random_followers_utenti_ids= {\"mizzaro\":[{}{}{}{}{}],\"damiano10\":[{}...}],...}\n",
    "\n",
    "for utente in following_ids:\n",
    "    random_following_utenti_ids[utente] = random.sample(following_ids[utente], 5)\n",
    "# result: random_following_utenti_ids= {\"mizzaro\":[{}{}{}{}{}],\"damiano10\":[{}...}],...}\n",
    "\n",
    "#Download dei followers dei 10 followers degli utenti random \n",
    "for utente in random_followers_utenti_ids:\n",
    "    for f in random_followers_utenti_ids[utente]:\n",
    "        fof = []\n",
    "        print(\"scarico per \" + str(utente))\n",
    "        for item in tweepy.Cursor(\n",
    "                api.followers,\n",
    "                id=f['id'],\n",
    "                skip_status=True,\n",
    "                include_user_entities=False\n",
    "        ).items(10):\n",
    "                time.sleep(10)\n",
    "                json_data = item._json\n",
    "                user = {\"id\": json_data[\"id\"]}\n",
    "                fof.append(user)\n",
    "                print(\"Downloaded: \" + str(user))\n",
    "\n",
    "\n",
    "        followers_of_followers_ids[f['id']] = fof\n",
    "\n",
    "serialize_json(\"data_ids/finale\", \"followers_of_followers.json\", followers_of_followers_ids)\n",
    "\n",
    "#Download dei following dei 10 following degli utenti random \n",
    "for utente in random_following_utenti_ids:\n",
    "    for f in random_following_utenti_ids[utente]:\n",
    "        fof = []\n",
    "        print(\"scarico per \" + str(utente))\n",
    "        for item in tweepy.Cursor(\n",
    "                api.friends,\n",
    "                id=f['id'],\n",
    "                skip_status=True,\n",
    "                include_user_entities=False\n",
    "        ).items(10):\n",
    "            time.sleep(10)\n",
    "            json_data = item._json\n",
    "            user = {\"id\": json_data[\"id\"]}\n",
    "            fof.append(user)\n",
    "            print(\"Downloaded: \" + str(user))\n",
    "\n",
    "        following_of_following_ids[f['id']] = fof\n",
    "\n",
    "serialize_json(\"data_ids/finale\", \"following_of_following.json\", following_of_following_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#3\n",
    "\n",
    "random_following_utenti_ids,following_of_following_ids={},{}\n",
    "\n",
    "for utente in following_ids:\n",
    "    random_following_utenti_ids[utente]=random.sample(following_ids[utente],5)\n",
    "\n",
    "try:\n",
    "    for utente in random_following_utenti_ids:\n",
    "        for f in random_following_utenti_ids[utente]:\n",
    "            fof=[]\n",
    "            time.sleep(10)\n",
    "            for item in tweepy.Cursor(\n",
    "                api.following,\n",
    "                id=f,\n",
    "                skip_status=True,\n",
    "                include_user_entities=False\n",
    "            ).items(10):\n",
    "                json_data=item._json\n",
    "                user={\"id\":json_data[\"id\"]}\n",
    "                fof.append(user)\n",
    "\n",
    "            following_of_following_ids[f[\"id\"]]=fof\n",
    "except tweepy.TweepError as error: #Le prime volte mi ha tornato TweepError:Unauthorized, ma ora non piÃ¹\n",
    "    print(error)\n",
    "serialize_json(\"data_ids/finale\",\"following_of_following.json\",following_of_following_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data read from path: data_ids/followers_5_utenti.json\n",
      "Data read from path: data_ids/following_5_utenti.json\n",
      "Data read from path: data_ids/followers_of_followers.json\n",
      "Data read from path: data_ids/following_of_following.json\n",
      "Json caricati\n"
     ]
    }
   ],
   "source": [
    "followers_ids=read_json(\"data_ids/followers_5_utenti.json\")\n",
    "following_ids=read_json(\"data_ids/following_5_utenti.json\")\n",
    "followers_of_followers_ids=read_json(\"data_ids/followers_of_followers.json\")\n",
    "following_of_following_ids=read_json(\"data_ids/following_of_following.json\")\n",
    "print(\"Json caricati\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[740410382]\n"
     ]
    }
   ],
   "source": [
    "#unione in unico json finale senza ripetizioni, tanto abbiamo giÃ  estratto i follower random ed Ã¨ piÃ¹ comodo per la chiamata api.show_friendship\n",
    "#Logicamente, se non fosse stato per la consegna, avremmo avuto giÃ  le relazioni scaricando i followers dei 5 nodi principali\n",
    "\n",
    "lista_json=[followers_ids,following_ids,followers_of_followers_ids,following_of_following_ids]\n",
    "id_nodi_revisionati=[]\n",
    "#print(lista_json)\n",
    "for json_2 in lista_json:\n",
    "    for utente in json_2:\n",
    "      #  print(utente)\n",
    "        for user_id in json_2[utente]:\n",
    "            if not user_id in id_nodi_revisionati:\n",
    "                id_nodi_revisionati.append(user_id['id'])\n",
    "\n",
    "print(id_nodi_revisionati[:1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{740410382: [{'name': 'á¼Î½-á¼ÏÏÎ®', 'screen_name': 'ColoursRiot', 'location': '', 'followers_count': 26, 'friends_count': 145, 'statuses_count': 874, 'created_at': 'Mon Aug 06 11:26:07 +0000 2012', 'profile_banner_url': 'https://pbs.twimg.com/profile_banners/740410382/1398799456'}]}\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'dump'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-45c9808910a3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0mserialize_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"data_ids\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"nodes_of_twitter_graph.json\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-44-2af639253ce7>\u001b[0m in \u001b[0;36mserialize_json\u001b[1;34m(folder, filename, data)\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{folder}/{filename}\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_ascii\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Data serialized to path: {folder}/{filename}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'dump'"
     ]
    }
   ],
   "source": [
    "#4 Scaricare i dati con api.get_user\n",
    "id_nodi_revisionati = id_nodi_revisionati[:1]\n",
    "nodes = {}\n",
    "    \n",
    "for user_id in id_nodi_revisionati: \n",
    "    node_info_of_id = []\n",
    "    \n",
    "    utente=api.get_user(id=user_id)._json\n",
    "    \n",
    "    node_infos= {} \n",
    "    node_infos[\"name\"]=utente[\"name\"]\n",
    "    node_infos[\"screen_name\"]=utente[\"screen_name\"]\n",
    "    node_infos[\"location\"]=utente[\"location\"]\n",
    "    node_infos[\"followers_count\"]=utente[\"followers_count\"]\n",
    "    node_infos[\"friends_count\"]=utente[\"friends_count\"]\n",
    "    node_infos[\"statuses_count\"]=utente[\"statuses_count\"]\n",
    "    node_infos[\"created_at\"]=utente[\"created_at\"]\n",
    "    node_infos[\"profile_banner_url\"]=utente[\"profile_banner_url\"]\n",
    "    node_info_of_id.append(node_infos)\n",
    "    \n",
    "    nodes[user_id] = node_info_of_id\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{740410382: [{'name': 'á¼Î½-á¼ÏÏÎ®', 'screen_name': 'ColoursRiot', 'location': '', 'followers_count': 26, 'friends_count': 145, 'statuses_count': 874, 'created_at': 'Mon Aug 06 11:26:07 +0000 2012', 'profile_banner_url': 'https://pbs.twimg.com/profile_banners/740410382/1398799456'}]}\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'dump'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-7c98f3c155e0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mserialize_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"data_ids\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"nodes_of_twitter_graph.json\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-44-2af639253ce7>\u001b[0m in \u001b[0;36mserialize_json\u001b[1;34m(folder, filename, data)\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{folder}/{filename}\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_ascii\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Data serialized to path: {folder}/{filename}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'dump'"
     ]
    }
   ],
   "source": [
    "print(nodes)    \n",
    "serialize_json(\"data_ids\", \"nodes_of_twitter_graph.json\", nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Creazione dataframe dei Nodi  (da adattare ai json)\n",
    "def create_node(user_follower):\n",
    "    #lettura json dell'utente desiderato\n",
    "    with open(user_follower+\"_followers.json\", \"r\", encoding=\"UTF-8\") as read_file:\n",
    "        data = json.load(read_file)\n",
    "    #aggiunta dei nodi\n",
    "    followers_nodes=[]\n",
    "    for result in data[user_follower]:\n",
    "        followers_nodes.append(result)  \n",
    "    #df_nodi_grafo\n",
    "    df_nodes = pd.DataFrame(followers_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creazione dataframe degli archi di follow\n",
    "def create_edges(follower): \n",
    "    #aggiunta degli archi\n",
    "    friendships= []\n",
    "    for result in friendship[relationship]\n",
    "        if(result[\"source\"][\"followed_by\"]== \"true\" | result[\"source\"][\"following\"]== \"true\" ):\n",
    "            if(result[\"source\"][\"followed_by\"] == true):\n",
    "                result[\"source\"] = result[\"source\"][\"id\"]\n",
    "                result[\"followed\"] = True\n",
    "            if(result[\"source\"][\"following\"] == true):\n",
    "                result[\"target\"] = result[\"target\"][\"id\"]\n",
    "                result[\"following\"] = True\n",
    "            friendships.append(result)\n",
    "\n",
    "#inserimento nel dataframe\n",
    "    df_edges = pd.DataFrame(friendships)\n",
    "    return df_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funzioni per la gestione dei dataframes (modifiche in base al formato dei json)\n",
    "\n",
    "#Unione tra due dataframe\n",
    "def dataframe_user(df_follower,df_following):\n",
    "    frames= [df_follower,df_following]\n",
    "    #unione dei dataframes tra followers e followings\n",
    "    df_user = pd.concat(frames)\n",
    "    return df_user\n",
    "\n",
    "#creazione del dataframe dato un array di screen_names\n",
    "def users_dfs(usernames):\n",
    "    columns=['id','name','screen_name','location']  \n",
    "    users_dfs = pd.DataFrame(columns=columns)\n",
    "    for user in usernames:\n",
    "        df_follower=user_followers_df(user)\n",
    "        df_following=user_following_df(user)\n",
    "        df_user=dataframe_user(df_follower,df_following)\n",
    "        users_dfs=dataframe_user(users_dfs,df_user)\n",
    "        \n",
    "    return users_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#5. Creazione del grafo\n",
    "#-->In teoria i nodi arrivano dai json con il solito schema\n",
    "#Aggiunta dei nodi al grafo\n",
    "twitter_graph = nx.DiGraph(team=\"Loris Parata 144338, Francesco Arzon 142439, Lorenzo Dal Fabbro, Matteo Galvan\")#non dobbiamo aggiungerci con tutte i parametri degli altri nodi?\n",
    "\n",
    "for index,row in df_nodes.iterrows():\n",
    "        twitter_graph.add_node(row[\"id\"],\n",
    "                        id= row[\"id\"],\n",
    "                        title= row[\"name\"],\n",
    "                        color =\"#ffff00\",\n",
    "                        physics=False,#rende la visualizzazone del grafo piÃ¹ leggera\n",
    "                        name=row['name'],\n",
    "                        screen_name=row['screen_name'],\n",
    "                        location=row['location'],\n",
    "                        followers_count=row[\"followers_count\"],\n",
    "                        following_count=row[\"following_count\"],\n",
    "                        numbero_of_twitts=row[\"statuses_count\"]#strano nome wtf\n",
    "                        )            \n",
    "\n",
    "#Aggiunta collegamenti al grafo\n",
    "for user_id in users_id:#5 profili\n",
    "    for utente in finale:#tutti gli altri\n",
    "            status=api.show_friendship(id_source=user_id,id_target=utente[\"id\"])\n",
    "            if status[1].following:#da [tutti gli altri] a [5 profili]\n",
    "                twitter_graph.add_edge(utente[\"id\"],user_id,\"follow_rec\"=True if status[0].following else False) #nel caso volessimo evidenziare il follow reciproco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#6 Creazione grafo interattivo con pyvis\n",
    "\n",
    "def disegna_grafo(grafo):\n",
    "    nt = Network(\n",
    "        height =\"50%\",\n",
    "        width = \"50%\",\n",
    "        bgcolor=\"#222222\",\n",
    "        font_color=\"white\",\n",
    "        heading= grafo,\n",
    "        directed=True,\n",
    "    )\n",
    "\n",
    "    nt.from_nx(grafo)\n",
    "    nt.barnes_hut()\n",
    "  # nt.set_edge_smooth(\"continuous\") #cambia formato di visualizzazione degli archi\n",
    "    neighbor_map = nt.get_adj_list()\n",
    "    \n",
    "    for node in nt.nodes:\n",
    "            node[\"value\"] = len(neighbor_map[node[\"id\"]])\n",
    "           # print(str(node[\"id\"])+\":\"+ str(node[\"value\"]))\n",
    "         \n",
    "    nt.show(\"grafo.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main\n",
    "\n",
    "#Array usernames dei nodi principali\n",
    "usernames=[\"miccighel_\",\"mizzaro\",\"damiano10\",\"eglu81\",\"KevinRoitero\"]\n",
    "df_users= users_dfs(usernames)\n",
    "#Creazione del grafo\n",
    "twitter_graph=following_graph(df_users)\n",
    "#print(fg.nodes().data())\n",
    "twitter_graph.number_of_edges()\n",
    "#disegna_grafo(following_graph(df.loc[df['id'] == 1527461]))\n",
    "#disegna_grafo(fg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#7 ProprietÃ  del grafo\n",
    "undirected_twitter_graph= nx.to_undirected(twitter_graph)\n",
    "\n",
    "if nx.is_connected(undirected_twitter_graph):\n",
    "    print(\"Il grafo Ã¨ connesso.\")\n",
    "else:\n",
    "    print(\"Il grafo non Ã¨ connesso.\")\n",
    "    \n",
    "if nx.is_bipartite(undirected_twitter_graph):\n",
    "    print(\"Il grafo Ã¨ bipartito.\")\n",
    "else:\n",
    "    print(\"Il grafo non Ã¨ bipartito.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#8 Distanze sul grafo\n",
    "centro = nx.center(twitter_graph)\n",
    "print(centro)\n",
    "diametro = nx.diameter(twitter_graph)\n",
    "print(diametro)\n",
    "raggio = nx.radius(twitter_graph)\n",
    "print(raggio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'twitter_graph' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-04c17def44f7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#9 Misure di centralitÃ  sul grafo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mbtw_centrality\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbetweenness_centrality\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtwitter_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbtw_centrality\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcls_centrality\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcloseness_centrality\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtwitter_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls_centralitu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'twitter_graph' is not defined"
     ]
    }
   ],
   "source": [
    "#9 Misure di centralitÃ  sul grafo\n",
    "btw_centrality = nx.betweenness_centrality(twitter_graph)\n",
    "print(btw_centrality)\n",
    "cls_centrality = nx.closeness_centrality(twitter_graph)\n",
    "print(cls_centralitu)\n",
    "dg_centrality = nx.degree_centrality(twitter_graph)\n",
    "print(dg_centrality)\n",
    "\n",
    "in_centrality= nx.in_degree_centrality(twitter_graph)\n",
    "print(in_centrality)\n",
    "out_centrality= nx.out_degree_centrality(twitter_graph)\n",
    "print(out_centrality)\n",
    "#valori di centralitÃ \n",
    "undirect_centralities=[btw_centrality,cls_centrality,dg_centrality]\n",
    "direct_centralities=[in_centrality,out_centrality]\n",
    "\n",
    "pagerank= nx.pagerank(twitter_graph)\n",
    "pagerank=sorted(pagerank.items(),key=lambda x:x[1],reverse=True)\n",
    "centralities= [btw_centrality,cls_centrality,dg_centrality,in_centrality,out_centrality]\n",
    "print(pagerank[:5])\n",
    "\n",
    "hits= nx.hits(twitter_graph)\n",
    "hits_hubs=hits[0]\n",
    "hits_hub= sorted(hits_hubs.items(),key=lambda x:x[1],reverse=True)\n",
    "print(hits_hub[:5])\n",
    "hits_authorities=hits[1]\n",
    "hits_authorities=sorted(hits_authorities.items(),key=lambda x:x[1],reverse=True)\n",
    "print(hits_authorities[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Sottografo del nodo damiano10\n",
    "sub_graph_damiano10 = nx.ego_graph(twitter_graph, \"damiano10\")\n",
    "disegna_grafo(sub_graph_damiano10)\n",
    "print(help(nx.clique))\n",
    "clique.max_clique(sub_graph_damiano10)\n",
    "print(nx.large_clique_size(sub_graph_damiano10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#11 copertua minima degli archi\n",
    "nx.min_edge_cover(twitter_graph)\n",
    "\n",
    "#12 Small-world-ness\n",
    "nx.omega(twitter_graph)\n",
    "nx.sigma(twitter_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#13 Correlazione di Pearson e di Kendall\n",
    "\n",
    "columns=[\"name\",\"value\"]\n",
    "centralita_df = pd.DataFrame(columns=columns)\n",
    "rows = [[\"btw_centrality\",btw_centrality],[\"cls_centrality\",cls_centrality],[\"dg_centrality\",dg_centrality],[\"in_centrality\",in_centrality],[\"out_centrality\",out_centrality]]\n",
    "#Creazione df contenente tipologia_misura : valore\n",
    "for row in rows:\n",
    "    centralita_df.loc[len(centralita_df)] = row\n",
    "#print(centralita_df)\n",
    "\n",
    "#Creazione df contenente  tipologia_misura_1 , tipologia_misura_2, valore_correlazione_1 , valore_correlazione_2\n",
    "columns=[\"name_1\",\"name_2\",\"pearson\", \"kendall\"]\n",
    "result= pd.DataFrame(columns=columns)\n",
    "\n",
    "for index, param_1 in centralita_df.iterrows():\n",
    "    for index, param_2 in centralita_df.iterrows():\n",
    "        if(param_1[\"name\"] != param_2[\"name\"]):\n",
    "            name_1= param_1[\"name\"]\n",
    "            name_2= param_2[\"name\"]\n",
    "            array_1= np.array(list(param_1[\"value\"].values()), dtype=float)\n",
    "            array_2= np.array(list(param_2[\"value\"].values()), dtype=float)\n",
    "            pearson= stats.pearsonr(array_1,array_2)\n",
    "            kendall= stats.kendalltau(array_1,array_2)\n",
    "            new_row = {\n",
    "            'name_1': name_1,\n",
    "            'name_2': name_2,\n",
    "            'pearson': pearson,\n",
    "            'kendall': kendall\n",
    "                }\n",
    "            result = result.append(new_row, ignore_index=True)\n",
    "\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
