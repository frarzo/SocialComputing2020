{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Librerie caricate!\n"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "import json\n",
    "from itertools import islice\n",
    "import os\n",
    "import time\n",
    "import pprint\n",
    "import requests\n",
    "import random\n",
    "import networkx as nx\n",
    "from networkx.algorithms.approximation import clique\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "from pyvis.network import Network\n",
    "import itertools \n",
    "\n",
    "print(\"Librerie caricate!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generiche funzioni e utilities\n",
    "\n",
    "data_folder = \"data_ids\"\n",
    "pp=pprint.PrettyPrinter()\n",
    "\n",
    "def serialize_json(folder, filename, data):\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder, exist_ok=True)\n",
    "    with open(f\"{folder}/{filename}\", 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "        f.close()\n",
    "    print(f\"Data serialized to path: {folder}/{filename}\")\n",
    "\n",
    "def read_json(path):\n",
    "    if os.path.exists(path):\n",
    "        with open(path, \"r\", encoding=\"utf8\") as file:\n",
    "            data = json.load(file)\n",
    "        print(f\"Data read from path: {path}\")\n",
    "        return data\n",
    "    else:\n",
    "        print(f\"No data found at path: {path}\")\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auth success\n"
     ]
    }
   ],
   "source": [
    "#Fase di autenticazione\n",
    "api_key=\"cvoM8D7hXXxlvBXTM8aH9X2ec\"\n",
    "api_secret=\"Uk2UvH0FJY7KaDzkXYLfgiYkA1OuCwbLlGFPyodB5wcQ5bsItN\"\n",
    "\n",
    "access_token=\"3303466053-OLuExo5KcP8UQCVwZwmyakZs8b91Fpl2lMOUDAe\"\n",
    "access_secret=\"1lMXufu42KN8JvJjYT7c0zI3Q57CkN09BxkNXZuNQ0Dej\"\n",
    "\n",
    "bearer_token=\"AAAAAAAAAAAAAAAAAAAAAHsVJQEAAAAAQ4vYb83r6ueD8QvjJ4Zpx9R7Kbw%3DQuLzsmDYOvpff7lRHGXhNJSOXTFuPyOwLHZv7HPSj9WF34h1E8\"\n",
    "\n",
    "auth=tweepy.OAuthHandler(api_key,api_secret)\n",
    "auth.set_access_token(access_token,access_secret)\n",
    "api=tweepy.API(auth,wait_on_rate_limit=True,wait_on_rate_limit_notify=True)\n",
    "if(api.verify_credentials):\n",
    "    print(\"Auth success\")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 41,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
=======
   "execution_count": 4,
   "metadata": {},
>>>>>>> parent of bbf6e69... Scrittura quasi completa della relazione
   "outputs": [],
   "source": [
    "users=[\"mizzaro\",\"damiano10\",\"miccighel_\",\"eglu81\",\"KevinRoitero\"]\n",
    "users_id=[18932422, 132646210, 15750573, 19659370, 3036907250]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Scaricamento degli IDs di followers/following dei 5 account principali\n",
    "followers_ids,following_ids={},{}\n",
    "\n",
    "for utente in users_id:\n",
    "    followers_utente,following_utente=[],[]\n",
    "    for item in tweepy.Cursor(\n",
    "        api.followers,\n",
    "        id=utente,\n",
    "        skip_status=True,\n",
    "        include_user_entities=False\n",
    "    ).items():\n",
    "        json_data=item._json\n",
    "        user={\"id\":json_data[\"id\"]}\n",
    "        time.sleep(181)\n",
    "        followers_utente.append(user)\n",
    "\n",
    "    followers_ids[utente]=followers_utente\n",
    "\n",
    "    for item in tweepy.Cursor(\n",
    "        api.friends,\n",
    "        id=utente,\n",
    "        skip_status=True,\n",
    "        include_user_entities=False\n",
    "    ).items():\n",
    "        json_data=item._json\n",
    "        user={\"id\":json_data[\"id\"]}\n",
    "        time.sleep(181)\n",
    "        following_utente.append(user)\n",
    "\n",
    "    following_ids[utente]=following_utente\n",
    "\n",
    "#followers_ids={\"mizzaro\":[123,456,789,...],\"damiano10\":[123,789,367,...],...}\n",
    "#export to json\n",
    "serialize_json(\"data\",\"followers_principali.json\",followers_ids)\n",
    "serialize_json(\"data\",\"following_principali.json\",following_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "followers_ids=read_json(\"data_ids/followers.json\")\n",
    "following_ids=read_json(\"data_ids/following.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "followers_ids, following_ids = [], []\n",
    "\n",
    "# punto 2&3\n",
    "followers_ids = read_json(\"/followers_5_utenti.json\")\n",
    "following_ids = read_json(\"/following_5_utenti.json\")\n",
    "\n",
    "# 2\n",
    "random_followers_utenti_ids, followers_of_followers_ids = {}, {}\n",
    "\n",
    "for utente in followers_ids:\n",
    "    random_followers_utenti_ids[utente] = random.sample(followers_ids[utente], 5)\n",
    "# result: random_followers_utenti_ids= {\"mizzaro\":[{}{}{}{}{}],\"damiano10\":[{}...}],...}\n",
    "\n",
    "for utente in following_ids:\n",
    "    random_following_utenti_ids[utente] = random.sample(following_ids[utente], 5)\n",
    "# result: random_following_utenti_ids= {\"mizzaro\":[{}{}{}{}{}],\"damiano10\":[{}...}],...}\n",
    "\n",
    "#Download dei followers dei 10 followers degli utenti random \n",
    "try:\n",
    "    for utente in random_followers_utenti_ids:\n",
    "        for f in random_followers_utenti_ids[utente]:\n",
    "            fof = []\n",
    "            print(\"scarico per \" + str(utente))\n",
    "            for item in tweepy.Cursor(\n",
    "                    api.followers,\n",
    "                    id=f['id'],\n",
    "                    skip_status=True,\n",
    "                    include_user_entities=False\n",
    "            ).items(10):\n",
    "                    time.sleep(10)\n",
    "                    json_data = item._json\n",
    "                    user = {\"id\": json_data[\"id\"]}\n",
    "                    fof.append(user)\n",
    "                    print(\"Downloaded: \" + str(user))\n",
    "\n",
    "            followers_of_followers_ids[f['id']] = fof\n",
    "except tweepy.TweepError as error:\n",
    "    print(error)\n",
    "serialize_json(\"data_ids/finale\", \"followers_of_followers.json\", followers_of_followers_ids)\n",
    "\n",
    "#Download dei following dei 10 following degli utenti random \n",
    "try:\n",
    "    for utente in random_following_utenti_ids:\n",
    "        for f in random_following_utenti_ids[utente]:\n",
    "            fof = []\n",
    "            print(\"scarico per \" + str(utente))\n",
    "            for item in tweepy.Cursor(\n",
    "                    api.friends,\n",
    "                    id=f['id'],\n",
    "                    skip_status=True,\n",
    "                    include_user_entities=False\n",
    "            ).items(10):\n",
    "                time.sleep(10)\n",
    "                json_data = item._json\n",
    "                user = {\"id\": json_data[\"id\"]}\n",
    "                fof.append(user)\n",
    "                print(\"Downloaded: \" + str(user))\n",
    "\n",
<<<<<<< HEAD
    "            following_of_following_ids[f['id']] = fof\n",
    "except tweepy.TweepError as error:\n",
    "    print(error)\n",
=======
    "\n",
    "        followers_of_followers_ids[f['id']] = fof\n",
    "\n",
    "serialize_json(\"data_ids/finale\", \"followers_of_followers.json\", followers_of_followers_ids)\n",
    "\n",
    "#Download dei following dei 10 following degli utenti random \n",
    "for utente in random_following_utenti_ids:\n",
    "    for f in random_following_utenti_ids[utente]:\n",
    "        fof = []\n",
    "        print(\"scarico per \" + str(utente))\n",
    "        for item in tweepy.Cursor(\n",
    "                api.friends,\n",
    "                id=f['id'],\n",
    "                skip_status=True,\n",
    "                include_user_entities=False\n",
    "        ).items(10):\n",
    "            time.sleep(10)\n",
    "            json_data = item._json\n",
    "            user = {\"id\": json_data[\"id\"]}\n",
    "            fof.append(user)\n",
    "            print(\"Downloaded: \" + str(user))\n",
    "\n",
    "        following_of_following_ids[f['id']] = fof\n",
    "\n",
>>>>>>> parent of bbf6e69... Scrittura quasi completa della relazione
    "serialize_json(\"data_ids/finale\", \"following_of_following.json\", following_of_following_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###########TODO: DA CANCELLARE ##############\n",
    "\n",
    "\n",
    "\"\"\"#3\n",
    "\n",
    "random_following_utenti_ids,following_of_following_ids={},{}\n",
    "\n",
    "for utente in following_ids:\n",
    "    random_following_utenti_ids[utente]=random.sample(following_ids[utente],5)\n",
    "\n",
    "try:\n",
    "    for utente in random_following_utenti_ids:\n",
    "        for f in random_following_utenti_ids[utente]:\n",
    "            fof=[]\n",
    "            time.sleep(10)\n",
    "            for item in tweepy.Cursor(\n",
    "                api.following,\n",
    "                id=f,\n",
    "                skip_status=True,\n",
    "                include_user_entities=False\n",
    "            ).items(10):\n",
    "                json_data=item._json\n",
    "                user={\"id\":json_data[\"id\"]}\n",
    "                fof.append(user)\n",
    "\n",
    "            following_of_following_ids[f[\"id\"]]=fof\n",
    "except tweepy.TweepError as error: #Le prime volte mi ha tornato TweepError:Unauthorized, ma ora non più\n",
    "    print(error)\n",
    "serialize_json(\"data_ids/finale\",\"following_of_following.json\",following_of_following_ids)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
<<<<<<< HEAD
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
=======
   "metadata": {},
>>>>>>> parent of bbf6e69... Scrittura quasi completa della relazione
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data read from path: data_ids/followers_5_utenti.json\n",
      "Data read from path: data_ids/following_5_utenti.json\n",
      "Data read from path: data_ids/followers_of_followers.json\n",
      "Data read from path: data_ids/following_of_following.json\n",
      "Json caricati\n"
     ]
    }
   ],
   "source": [
    "#Caricamento json contenente tutti gli ID dei nodi interessati\n",
    "followers_ids=read_json(\"data_ids/followers_5_utenti.json\")\n",
    "following_ids=read_json(\"data_ids/following_5_utenti.json\")\n",
    "followers_of_followers_ids=read_json(\"data_ids/followers_of_followers.json\")\n",
    "following_of_following_ids=read_json(\"data_ids/following_of_following.json\")\n",
    "\n",
    "print(\"Json caricati\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1583\n",
      "3103\n"
     ]
    }
   ],
   "source": [
    "#unione in unico json finale \n",
    "lista_json=[followers_ids,following_ids, followers_of_followers_ids,following_of_following_ids]\n",
    "\n",
    "\n",
    "id_nodi_grafo=[]\n",
    "duplicati = 0\n",
    "#Eliminazione duplicati e conteggio di essi.\n",
    "for jsonn in lista_json:\n",
    "    for user in jsonn:\n",
    "        for user_id in jsonn[user]:\n",
    "            if user_id in id_nodi_grafo:\n",
    "                duplicati+=1\n",
    "            else:\n",
    "                id_nodi_grafo.append(user_id)\n",
    "print(duplicati)\n",
    "print(len(id_nodi_grafo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
=======
   "metadata": {},
>>>>>>> parent of bbf6e69... Scrittura quasi completa della relazione
   "outputs": [],
   "source": [
    "#4 Scaricare i dati con api.get_user\n",
    "\n",
    "nodes = {}\n",
    "    \n",
    "for user_id in id_nodi_grafo: \n",
    "   \n",
    "    #richiamo API GET_USER\n",
    "    utente=api.get_user(id=user_id)._json\n",
    "    node_infos= {} \n",
    "    \n",
    "    node_infos[\"name\"]=utente[\"name\"]\n",
    "    node_infos[\"screen_name\"]=utente[\"screen_name\"]\n",
    "    node_infos[\"location\"]=utente[\"location\"]\n",
    "    node_infos[\"followers_count\"]=utente[\"followers_count\"]\n",
    "    node_infos[\"friends_count\"]=utente[\"friends_count\"]\n",
    "    node_infos[\"statuses_count\"]=utente[\"statuses_count\"]\n",
    "    node_infos[\"created_at\"]=utente[\"created_at\"]\n",
    "   \n",
    "    nodes[user_id] = node_infos\n",
    "    \n",
    "print(\"download effettuato\")\n",
    "serialize_json(\"data_ids\", \"nodes_of_twitter_graph.json\", nodes)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 104,
=======
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data read from path: data_ids/api_show_friendship/damiano_edges.json\n",
      "Data read from path: data_ids/api_show_friendship/eglu_edges.json\n",
      "Data read from path: data_ids/api_show_friendship/kevin_edges.json\n",
      "Data read from path: data_ids/api_show_friendship/micch_edges.json\n",
      "Data read from path: data_ids/api_show_friendship/mizzaro_edges.json\n",
      "Data serialized to path: data_ids/edges_of_twitter_graph.json\n"
     ]
    }
   ],
   "source": [
    "#Unione delle relazioni scaricate per ogni utente, necessario per parallelizzare il download\n",
    "damiano_edges=read_json(\"data_ids/api_show_friendship/damiano_edges.json\")\n",
    "eglu_edges=read_json(\"data_ids/api_show_friendship/eglu_edges.json\")\n",
    "kevin_edges=read_json(\"data_ids/api_show_friendship/kevin_edges.json\")\n",
    "micch_edges=read_json(\"data_ids/api_show_friendship/micch_edges.json\")\n",
    "mizzaro_edges=read_json(\"data_ids/api_show_friendship/mizzaro_edges.json\")\n",
    "\n",
    "lista_edges=[damiano_edges,eglu_edges, kevin_edges,micch_edges,mizzaro_edges]\n",
    "\n",
    "main_edges = []\n",
    "#Unione json\n",
    "for main in lista_edges:\n",
    "    for relation in main:\n",
    "        main_edges.append(relation)\n",
    "serialize_json(\"data_ids\", \"edges_of_twitter_graph.json\", main_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
>>>>>>> parent of bbf6e69... Scrittura quasi completa della relazione
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data read from path: data_ids/nodes_of_twitter_graph.json\n",
      "Data read from path: data_ids/followers.json\n"
     ]
    }
   ],
   "source": [
    "#5. Creazione del grafo\n",
    "twitter_graph = nx.DiGraph(team=\"Loris Parata 144338, Francesco Arzon 142439, Lorenzo Dal Fabbro, Matteo Galvan\")\n",
    "#Aggiunta dei nodi al grafo\n",
    "nodes_of_graph=read_json(\"data_ids/nodes_of_twitter_graph.json\")\n",
    "for ids, node in nodes_of_graph.items():\n",
    "        \n",
    "        twitter_graph.add_node(ids,\n",
    "                               id= ids,\n",
    "                               title= node[\"name\"],\n",
    "                               color =\"#ffff00\",\n",
    "                               physics=False,#rende la visualizzazone del grafo più leggera\n",
    "                               name=node['name'],\n",
    "                               screen_name=node['screen_name'],\n",
    "                               location=node['location'],\n",
    "                               followers_count=node[\"followers_count\"],\n",
    "                               following_count=node[\"friends_count\"],\n",
    "                               number_of_twitts=node[\"statuses_count\"],\n",
    "                               data_creazione_profilo=node[\"created_at\"]\n",
    "                              )            \n",
    "edges=read_json(\"data_ids/followers.json\")\n",
    "archi= []\n",
    "presente = 0\n",
    "num = 0\n",
    "\n",
    "for ids, edge in edges.items():\n",
    "    for n in range(0,len(edge)-1):\n",
    "        if twitter_graph.has_node(str(edge[n]['id'])):\n",
    "           #print(edge[n]['id'])\n",
    "           #print(ids)\n",
    "            twitter_graph.add_edge(str(edge[n]['id']),ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3103\n",
      "1904\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(twitter_graph.number_of_nodes())\n",
    "print(twitter_graph.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "disegna_grafo(twitter_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
=======
   "execution_count": 8,
>>>>>>> parent of bbf6e69... Scrittura quasi completa della relazione
   "metadata": {},
   "outputs": [],
   "source": [
    "#6 Creazione grafo interattivo con pyvis\n",
    "\n",
    "def disegna_grafo(grafo):\n",
    "    nt = Network(\n",
    "        height =\"80%\",\n",
    "        width = \"80%\",\n",
    "        bgcolor=\"#222222\",\n",
    "        font_color=\"white\",\n",
    "        heading= grafo,\n",
    "        directed=True,\n",
    "    )\n",
    "    nt.show_buttons(filter_=None)\n",
    "    nt.from_nx(grafo)\n",
    "   # nt.barnes_hut()\n",
    "    nt.inherit_edge_colors(False)\n",
    "  # nt.set_edge_smooth(\"continuous\") #cambia formato di visualizzazione degli archi\n",
    "    neighbor_map = nt.get_adj_list()\n",
    "    \n",
    "    for node in nt.nodes:\n",
    "            node[\"value\"] = len(neighbor_map[node[\"id\"]])\n",
    "           # print(str(node[\"id\"])+\":\"+ str(node[\"value\"]))\n",
    "         \n",
<<<<<<< HEAD
    "    nt.show(\"grafo.html\")\n"
=======
    "    nt.show(\"grafo.html\")\n",
    "\n",
    "disegna_grafo(twitter_graph)"
>>>>>>> parent of bbf6e69... Scrittura quasi completa della relazione
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Main\n",
    "\n",
    "#Array usernames dei nodi principali\n",
    "usernames=[\"miccighel_\",\"mizzaro\",\"damiano10\",\"eglu81\",\"KevinRoitero\"]\n",
    "df_users= users_dfs(usernames)\n",
    "#Creazione del grafo\n",
    "twitter_graph=following_graph(df_users)\n",
    "#print(fg.nodes().data())\n",
    "twitter_graph.number_of_edges()\n",
    "#disegna_grafo(following_graph(df.loc[df['id'] == 1527461]))\n",
    "#disegna_grafo(fg)"
=======
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero nodi del grafo completo\n",
      "3103\n",
      "Numero archi del grafo completo\n",
      "1922\n",
      "Numero di nodi eliminati\n",
      "1424\n",
      "Numero dei nodi del grafo connesso\n",
      "1679\n"
     ]
    }
   ],
   "source": [
    "#Rimozione dei nodi sconnessi per ottenere un sotto grafo connesso\n",
    "print(\"Numero nodi del grafo completo\")\n",
    "print(twitter_graph.number_of_nodes())\n",
    "print(\"Numero archi del grafo completo\")\n",
    "print(twitter_graph.number_of_edges())\n",
    "\n",
    "#Creo una copia del grafo\n",
    "sub_twitter_graph =twitter_graph.copy()\n",
    "\n",
    "nodes_to_delete=[]\n",
    "#Controlla se un nodo ha out_degree = 0,\n",
    "#perchè ci interessano solo i nodi che seguono un account principale\n",
    "for node_id in twitter_graph.nodes():\n",
    "    if(twitter_graph.out_degree[node_id] == 0):\n",
    "        nodes_to_delete.append(node_id)\n",
    "sub_twitter_graph.remove_nodes_from(nodes_to_delete)\n",
    "\n",
    "print(\"Numero di nodi eliminati\")        \n",
    "print(len(nodes_to_delete))\n",
    "print(\"Numero dei nodi del grafo connesso\")\n",
    "print(sub_twitter_graph.number_of_nodes())\n",
    "\n",
    "#disegna_grafo(sub_twitter_graph)"
>>>>>>> parent of bbf6e69... Scrittura quasi completa della relazione
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
=======
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il grafo non è connesso.\n",
      "Il grafo non è bipartito.\n"
     ]
    }
   ],
>>>>>>> parent of bbf6e69... Scrittura quasi completa della relazione
   "source": [
    "#7 Proprietà del grafo\n",
    "undirected_twitter_graph= nx.to_undirected(twitter_graph)\n",
    "\n",
    "if nx.is_connected(undirected_twitter_graph):\n",
    "    print(\"Il grafo è connesso.\")\n",
    "else:\n",
    "    print(\"Il grafo non è connesso.\")\n",
    "    \n",
    "if nx.is_bipartite(undirected_twitter_graph):\n",
    "    print(\"Il grafo è bipartito.\")\n",
    "else:\n",
    "    print(\"Il grafo non è bipartito.\")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
=======
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il grafo è connesso.\n",
      "Il grafo non è bipartito.\n"
     ]
    }
   ],
>>>>>>> parent of bbf6e69... Scrittura quasi completa della relazione
   "source": [
    "#8 Distanze sul grafo\n",
    "centro = nx.center(twitter_graph)\n",
    "print(centro)\n",
    "diametro = nx.diameter(twitter_graph)\n",
    "print(diametro)\n",
    "raggio = nx.radius(twitter_graph)\n",
    "print(raggio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3036907250', '19659370', '132646210']\n",
      "4\n",
      "2\n"
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "#9 Misure di centralità sul grafo\n",
=======
    "#8 Distanze sul grafo connesso, ma unidirected, perchè non è fortemente connesso\n",
    "centro = nx.center(undirected_sub_twitter_graph)\n",
    "print(centro)\n",
    "diametro = nx.diameter(undirected_sub_twitter_graph)\n",
    "print(diametro)\n",
    "raggio = nx.radius(undirected_sub_twitter_graph)\n",
    "print(raggio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('132646210', 0.21591069996122966), ('19659370', 0.1725877527748354), ('18932422', 0.15167350993349105), ('3036907250', 0.12028088718016337), ('15750573', 0.09360836674428007)]\n",
      "[('94732055', 0.001547318026404474), ('14451127', 0.001547318026404474), ('810893744593584128', 0.001547318026404474), ('125483940', 0.001547318026404474), ('2190533245', 0.001547318026404474)]\n",
      "[('132646210', 0.6243701263224811), ('19659370', 0.23790522256888028), ('18932422', 0.08980472460682286), ('3036907250', 0.03981708773451595), ('15750573', 0.008102838767299813)]\n"
     ]
    }
   ],
   "source": [
    "#9 Misure di centralità sul grafo completo\n",
>>>>>>> parent of bbf6e69... Scrittura quasi completa della relazione
    "btw_centrality = nx.betweenness_centrality(twitter_graph)\n",
    "print(btw_centrality)\n",
    "cls_centrality = nx.closeness_centrality(twitter_graph)\n",
    "print(cls_centralitu)\n",
    "dg_centrality = nx.degree_centrality(twitter_graph)\n",
    "print(dg_centrality)\n",
    "\n",
    "in_centrality= nx.in_degree_centrality(twitter_graph)\n",
    "print(in_centrality)\n",
    "out_centrality= nx.out_degree_centrality(twitter_graph)\n",
    "print(out_centrality)\n",
    "#valori di centralità\n",
    "undirect_centralities=[btw_centrality,cls_centrality,dg_centrality]\n",
    "direct_centralities=[in_centrality,out_centrality]\n",
    "\n",
    "pagerank= nx.pagerank(twitter_graph)\n",
    "pagerank=sorted(pagerank.items(),key=lambda x:x[1],reverse=True)\n",
    "centralities= [btw_centrality,cls_centrality,dg_centrality,in_centrality,out_centrality]\n",
    "print(pagerank[:5])\n",
    "\n",
    "hits= nx.hits(twitter_graph)\n",
    "hits_hubs=hits[0]\n",
    "hits_hub= sorted(hits_hubs.items(),key=lambda x:x[1],reverse=True)\n",
    "print(hits_hub[:5])\n",
    "hits_authorities=hits[1]\n",
    "hits_authorities=sorted(hits_authorities.items(),key=lambda x:x[1],reverse=True)\n",
    "print(hits_authorities[:5])"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
=======
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('132646210', 0.24344350091927122), ('19659370', 0.19459372341628542), ('18932422', 0.1712035495617394), ('3036907250', 0.13565158508066366), ('15750573', 0.10555433548306957)]\n",
      "[('94732055', 0.001547318026404474), ('14451127', 0.001547318026404474), ('810893744593584128', 0.001547318026404474), ('125483940', 0.001547318026404474), ('2190533245', 0.001547318026404474)]\n",
      "[('132646210', 0.6243701263224811), ('19659370', 0.23790522256888028), ('18932422', 0.08980472460682286), ('3036907250', 0.03981708773451595), ('15750573', 0.008102838767299813)]\n"
     ]
    }
   ],
   "source": [
    "#9 Misure di centralità sul sotto-grafo\n",
    "btw_centrality = nx.betweenness_centrality(sub_twitter_graph)\n",
    "#print(btw_centrality)\n",
    "cls_centrality = nx.closeness_centrality(sub_twitter_graph)\n",
    "#print(cls_centralitu)\n",
    "dg_centrality = nx.degree_centrality(sub_twitter_graph)\n",
    "#print(dg_centrality)\n",
    "\n",
    "in_centrality= nx.in_degree_centrality(sub_twitter_graph)\n",
    "#print(in_centrality)\n",
    "out_centrality= nx.out_degree_centrality(sub_twitter_graph)\n",
    "#print(out_centrality)\n",
    "#valori di centralità\n",
    "undirect_centralities=[btw_centrality,cls_centrality,dg_centrality]\n",
    "direct_centralities=[in_centrality,out_centrality]\n",
    "\n",
    "pagerank= nx.pagerank(sub_twitter_graph)\n",
    "pagerank=sorted(pagerank.items(),key=lambda x:x[1],reverse=True)\n",
    "centralities= [btw_centrality,cls_centrality,dg_centrality,in_centrality,out_centrality]\n",
    "print(pagerank[:5])\n",
    "\n",
    "hits= nx.hits(sub_twitter_graph)\n",
    "hits_hubs=hits[0]\n",
    "hits_hub= sorted(hits_hubs.items(),key=lambda x:x[1],reverse=True)\n",
    "print(hits_hub[:5])\n",
    "hits_authorities=hits[1]\n",
    "hits_authorities=sorted(hits_authorities.items(),key=lambda x:x[1],reverse=True)\n",
    "print(hits_authorities[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'132646210', '15455450', '19659370', '18932422'}\n"
     ]
>>>>>>> parent of bbf6e69... Scrittura quasi completa della relazione
    }
   },
   "outputs": [],
   "source": [
    "#Sottografo del nodo KevinRoitero\n",
<<<<<<< HEAD
    "sub_graph_KevinRoitero = nx.ego_graph(twitter_graph, \"KevinRoitero\")\n",
    "disegna_grafo(sub_graph_KevinRoitero)\n",
    "clique.max_clique(sub_graph_KevinRoitero)\n",
    "print(nx.large_clique_size(sub_graph_KevinRoitero))"
=======
    "sub_graph_KevinRoitero = nx.ego_graph(sub_twitter_graph, \"3036907250\", undirected= True)\n",
    "disegna_grafo(sub_graph_KevinRoitero)\n",
    "print(clique.max_clique(sub_graph_KevinRoitero))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#11 copertua minima degli archi\n",
    "nx.min_edge_cover(undirected_twitter_graph)\n"
>>>>>>> parent of bbf6e69... Scrittura quasi completa della relazione
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "#11 copertua minima degli archi\n",
    "nx.min_edge_cover(twitter_graph)\n",
    "\n",
    "#12 Small-world-ness\n",
    "nx.omega(twitter_graph)\n",
    "nx.sigma(twitter_graph)"
=======
    "#12 Small-world-ness\n",
    "omega=nx.omega(undirected_twitter_graph, niter=20, nrand=5)\n",
    "print(omega)\n",
    "sigma=nx.sigma(undirected_twitter_graph,niter=20, nrand=5)\n",
    "print(sigma)"
>>>>>>> parent of bbf6e69... Scrittura quasi completa della relazione
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
=======
   "metadata": {},
>>>>>>> parent of bbf6e69... Scrittura quasi completa della relazione
   "outputs": [],
   "source": [
    "#13 Correlazione di Pearson e di Kendall\n",
    "\n",
    "columns=[\"name\",\"value\"]\n",
    "centralita_df = pd.DataFrame(columns=columns)\n",
    "rows = [[\"btw_centrality\",btw_centrality],[\"cls_centrality\",cls_centrality],[\"dg_centrality\",dg_centrality],[\"in_centrality\",in_centrality],[\"out_centrality\",out_centrality]]\n",
    "#Creazione df contenente tipologia_misura : valore\n",
    "for row in rows:\n",
    "    centralita_df.loc[len(centralita_df)] = row\n",
    "#print(centralita_df)\n",
    "\n",
    "#Creazione df contenente  tipologia_misura_1 , tipologia_misura_2, valore_correlazione_1 , valore_correlazione_2\n",
    "columns=[\"name_1\",\"name_2\",\"pearson\", \"kendall\"]\n",
    "result= pd.DataFrame(columns=columns)\n",
    "\n",
    "for index, param_1 in centralita_df.iterrows():\n",
    "    for index, param_2 in centralita_df.iterrows():\n",
    "        if(param_1[\"name\"] != param_2[\"name\"]):\n",
    "            name_1= param_1[\"name\"]\n",
    "            name_2= param_2[\"name\"]\n",
    "            array_1= np.array(list(param_1[\"value\"].values()), dtype=float)\n",
    "            array_2= np.array(list(param_2[\"value\"].values()), dtype=float)\n",
    "            pearson= stats.pearsonr(array_1,array_2)\n",
    "            kendall= stats.kendalltau(array_1,array_2)\n",
    "            new_row = {\n",
    "            'name_1': name_1,\n",
    "            'name_2': name_2,\n",
    "            'pearson': pearson,\n",
    "            'kendall': kendall\n",
    "                }\n",
    "            result = result.append(new_row, ignore_index=True)\n",
    "\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}