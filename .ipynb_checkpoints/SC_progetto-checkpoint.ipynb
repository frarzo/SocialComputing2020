{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Librerie caricate!\n"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "import json\n",
    "from itertools import islice\n",
    "import os\n",
    "import time\n",
    "import pprint\n",
    "import requests\n",
    "import random\n",
    "import networkx as nx\n",
    "from networkx.algorithms.approximation import clique\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "from pyvis.network import Network\n",
    "import itertools \n",
    "\n",
    "print(\"Librerie caricate!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "data_folder = \"data_ids\"\n",
    "pp=pprint.PrettyPrinter()\n",
    "\n",
    "def serialize_json(folder, filename, data):\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder, exist_ok=True)\n",
    "    with open(f\"{folder}/{filename}\", 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "        f.close()\n",
    "    print(f\"Data serialized to path: {folder}/{filename}\")\n",
    "\n",
    "def read_json(path):\n",
    "    if os.path.exists(path):\n",
    "        with open(path, \"r\", encoding=\"utf8\") as file:\n",
    "            data = json.load(file)\n",
    "        print(f\"Data read from path: {path}\")\n",
    "        return data\n",
    "    else:\n",
    "        print(f\"No data found at path: {path}\")\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auth success\n"
     ]
    }
   ],
   "source": [
    "#Fase di autenticazione\n",
    "api_key=\"cvoM8D7hXXxlvBXTM8aH9X2ec\"\n",
    "api_secret=\"Uk2UvH0FJY7KaDzkXYLfgiYkA1OuCwbLlGFPyodB5wcQ5bsItN\"\n",
    "\n",
    "access_token=\"3303466053-OLuExo5KcP8UQCVwZwmyakZs8b91Fpl2lMOUDAe\"\n",
    "access_secret=\"1lMXufu42KN8JvJjYT7c0zI3Q57CkN09BxkNXZuNQ0Dej\"\n",
    "\n",
    "bearer_token=\"AAAAAAAAAAAAAAAAAAAAAHsVJQEAAAAAQ4vYb83r6ueD8QvjJ4Zpx9R7Kbw%3DQuLzsmDYOvpff7lRHGXhNJSOXTFuPyOwLHZv7HPSj9WF34h1E8\"\n",
    "\n",
    "auth=tweepy.OAuthHandler(api_key,api_secret)\n",
    "auth.set_access_token(access_token,access_secret)\n",
    "api=tweepy.API(auth,wait_on_rate_limit=True,wait_on_rate_limit_notify=True)\n",
    "if(api.verify_credentials):\n",
    "    print(\"Auth success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "users=[\"mizzaro\",\"damiano10\",\"miccighel_\",\"eglu81\",\"KevinRoitero\"]\n",
    "users_id=[18932422, 132646210, 15750573, 19659370, 3036907250]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#1. Scaricate\n",
    "#codice da non eseguire a meno che non vogliate bruciarvi tutte le richieste di twitter API\n",
    "followers_ids,following_ids={},{}\n",
    "\n",
    "for utente in users_id:\n",
    "    followers_utente,following_utente=[],[]\n",
    "    for item in tweepy.Cursor(\n",
    "        api.followers,\n",
    "        id=utente,\n",
    "        skip_status=True,\n",
    "        include_user_entities=False\n",
    "    ).items():\n",
    "        json_data=item._json\n",
    "        user={\"id\":json_data[\"id\"]}\n",
    "        time.sleep(181)\n",
    "        followers_utente.append(user)\n",
    "\n",
    "    followers_ids[utente]=followers_utente\n",
    "\n",
    "    for item in tweepy.Cursor(\n",
    "        api.friends,\n",
    "        id=utente,\n",
    "        skip_status=True,\n",
    "        include_user_entities=False\n",
    "    ).items():\n",
    "        json_data=item._json\n",
    "        user={\"id\":json_data[\"id\"]}\n",
    "        time.sleep(181)\n",
    "        following_utente.append(user)\n",
    "\n",
    "    following_ids[utente]=following_utente\n",
    "\n",
    "#followers_ids={\"mizzaro\":[123,456,789,...],\"damiano10\":[123,789,367,...],...}\n",
    "#export to json\n",
    "serialize_json(\"data\",\"followers_principali.json\",followers_ids)\n",
    "serialize_json(\"data\",\"following_principali.json\",following_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "followers_ids=read_json(\"data_ids/followers.json\")\n",
    "following_ids=read_json(\"data_ids/following.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "followers_ids, following_ids = [], []\n",
    "\n",
    "# punto 2&3\n",
    "followers_ids = read_json(\"/followers_5_utenti.json\")\n",
    "following_ids = read_json(\"/following_5_utenti.json\")\n",
    "\n",
    "# 2\n",
    "random_followers_utenti_ids, followers_of_followers_ids = {}, {}\n",
    "\n",
    "for utente in followers_ids:\n",
    "    random_followers_utenti_ids[utente] = random.sample(followers_ids[utente], 5)\n",
    "# result: random_followers_utenti_ids= {\"mizzaro\":[{}{}{}{}{}],\"damiano10\":[{}...}],...}\n",
    "\n",
    "for utente in following_ids:\n",
    "    random_following_utenti_ids[utente] = random.sample(following_ids[utente], 5)\n",
    "# result: random_following_utenti_ids= {\"mizzaro\":[{}{}{}{}{}],\"damiano10\":[{}...}],...}\n",
    "\n",
    "#Download dei followers dei 10 followers degli utenti random \n",
    "for utente in random_followers_utenti_ids:\n",
    "    for f in random_followers_utenti_ids[utente]:\n",
    "        fof = []\n",
    "        print(\"scarico per \" + str(utente))\n",
    "        for item in tweepy.Cursor(\n",
    "                api.followers,\n",
    "                id=f['id'],\n",
    "                skip_status=True,\n",
    "                include_user_entities=False\n",
    "        ).items(10):\n",
    "                time.sleep(10)\n",
    "                json_data = item._json\n",
    "                user = {\"id\": json_data[\"id\"]}\n",
    "                fof.append(user)\n",
    "                print(\"Downloaded: \" + str(user))\n",
    "\n",
    "\n",
    "        followers_of_followers_ids[f['id']] = fof\n",
    "\n",
    "serialize_json(\"data_ids/finale\", \"followers_of_followers.json\", followers_of_followers_ids)\n",
    "\n",
    "#Download dei following dei 10 following degli utenti random \n",
    "for utente in random_following_utenti_ids:\n",
    "    for f in random_following_utenti_ids[utente]:\n",
    "        fof = []\n",
    "        print(\"scarico per \" + str(utente))\n",
    "        for item in tweepy.Cursor(\n",
    "                api.friends,\n",
    "                id=f['id'],\n",
    "                skip_status=True,\n",
    "                include_user_entities=False\n",
    "        ).items(10):\n",
    "            time.sleep(10)\n",
    "            json_data = item._json\n",
    "            user = {\"id\": json_data[\"id\"]}\n",
    "            fof.append(user)\n",
    "            print(\"Downloaded: \" + str(user))\n",
    "\n",
    "        following_of_following_ids[f['id']] = fof\n",
    "\n",
    "serialize_json(\"data_ids/finale\", \"following_of_following.json\", following_of_following_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#3\n",
    "\n",
    "random_following_utenti_ids,following_of_following_ids={},{}\n",
    "\n",
    "for utente in following_ids:\n",
    "    random_following_utenti_ids[utente]=random.sample(following_ids[utente],5)\n",
    "\n",
    "try:\n",
    "    for utente in random_following_utenti_ids:\n",
    "        for f in random_following_utenti_ids[utente]:\n",
    "            fof=[]\n",
    "            time.sleep(10)\n",
    "            for item in tweepy.Cursor(\n",
    "                api.following,\n",
    "                id=f,\n",
    "                skip_status=True,\n",
    "                include_user_entities=False\n",
    "            ).items(10):\n",
    "                json_data=item._json\n",
    "                user={\"id\":json_data[\"id\"]}\n",
    "                fof.append(user)\n",
    "\n",
    "            following_of_following_ids[f[\"id\"]]=fof\n",
    "except tweepy.TweepError as error: #Le prime volte mi ha tornato TweepError:Unauthorized, ma ora non pi√π\n",
    "    print(error)\n",
    "serialize_json(\"data_ids/finale\",\"following_of_following.json\",following_of_following_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data read from path: data_ids/followers_5_utenti.json\n",
      "Data read from path: data_ids/following_5_utenti.json\n",
      "Data read from path: data_ids/followers_of_followers.json\n",
      "Data read from path: data_ids/following_of_following.json\n",
      "Json caricati\n"
     ]
    }
   ],
   "source": [
    "#Caricamento json contenente tutti gli ID dei nodi interessati\n",
    "followers_ids=read_json(\"data_ids/followers_5_utenti.json\")\n",
    "following_ids=read_json(\"data_ids/following_5_utenti.json\")\n",
    "followers_of_followers_ids=read_json(\"data_ids/followers_of_followers.json\")\n",
    "following_of_following_ids=read_json(\"data_ids/following_of_following.json\")\n",
    "\n",
    "print(\"Json caricati\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1583\n",
      "3103\n"
     ]
    }
   ],
   "source": [
    "#unione in unico json finale \n",
    "lista_json=[followers_ids,following_ids, followers_of_followers_ids,following_of_following_ids]\n",
    "\n",
    "\n",
    "id_nodi_grafo=[]\n",
    "duplicati = 0\n",
    "#Eliminazione duplicati e conteggio di essi.\n",
    "for jsonn in lista_json:\n",
    "    for user in jsonn:\n",
    "        for user_id in jsonn[user]:\n",
    "            if user_id in id_nodi_grafo:\n",
    "                duplicati+=1\n",
    "            else:\n",
    "                id_nodi_grafo.append(user_id)\n",
    "print(duplicati)\n",
    "print(len(id_nodi_grafo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#4 Scaricare i dati con api.get_user\n",
    "\n",
    "nodes = {}\n",
    "    \n",
    "for user_id in id_nodi_grafo: \n",
    "   \n",
    "    #richiamo API GET_USER\n",
    "    utente=api.get_user(id=user_id)._json\n",
    "    node_infos= {} \n",
    "    \n",
    "    node_infos[\"name\"]=utente[\"name\"]\n",
    "    node_infos[\"screen_name\"]=utente[\"screen_name\"]\n",
    "    node_infos[\"location\"]=utente[\"location\"]\n",
    "    node_infos[\"followers_count\"]=utente[\"followers_count\"]\n",
    "    node_infos[\"friends_count\"]=utente[\"friends_count\"]\n",
    "    node_infos[\"statuses_count\"]=utente[\"statuses_count\"]\n",
    "    node_infos[\"created_at\"]=utente[\"created_at\"]\n",
    "   \n",
    "    nodes[user_id] = node_infos\n",
    "    \n",
    "print(\"download effettuato\")\n",
    "serialize_json(\"data_ids\", \"nodes_of_twitter_graph.json\", nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data read from path: data_ids/nodes_of_twitter_graph.json\n",
      "Data read from path: data_ids/followers.json\n"
     ]
    }
   ],
   "source": [
    "#5. Creazione del grafo\n",
    "twitter_graph = nx.DiGraph(team=\"Loris Parata 144338, Francesco Arzon 142439, Lorenzo Dal Fabbro, Matteo Galvan\")\n",
    "#Aggiunta dei nodi al grafo\n",
    "nodes_of_graph=read_json(\"data_ids/nodes_of_twitter_graph.json\")\n",
    "for ids, node in nodes_of_graph.items():\n",
    "        \n",
    "        twitter_graph.add_node(ids,\n",
    "                               id= ids,\n",
    "                               title= node[\"name\"],\n",
    "                               color =\"#ffff00\",\n",
    "                               physics=False,#rende la visualizzazone del grafo pi√π leggera\n",
    "                               name=node['name'],\n",
    "                               screen_name=node['screen_name'],\n",
    "                               location=node['location'],\n",
    "                               followers_count=node[\"followers_count\"],\n",
    "                               following_count=node[\"friends_count\"],\n",
    "                               number_of_twitts=node[\"statuses_count\"],\n",
    "                               data_creazione_profilo=node[\"created_at\"]\n",
    "                              )            \n",
    "edges=read_json(\"data_ids/followers.json\")\n",
    "archi= []\n",
    "presente = 0\n",
    "num = 0\n",
    "\n",
    "for ids, edge in edges.items():\n",
    "    for n in range(0,len(edge)-1):\n",
    "        if twitter_graph.has_node(str(edge[n]['id'])):\n",
    "           #print(edge[n]['id'])\n",
    "           #print(ids)\n",
    "            twitter_graph.add_edge(str(edge[n]['id']),ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3103\n",
      "1904\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(twitter_graph.number_of_nodes())\n",
    "print(twitter_graph.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Network' object has no attribute 'set_edge_minimization'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-116-5af1372d29db>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdisegna_grafo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtwitter_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-115-a334bd814fdc>\u001b[0m in \u001b[0;36mdisegna_grafo\u001b[1;34m(grafo)\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mdirected\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     )\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mnt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_edge_minimization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mnt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_nx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrafo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m    \u001b[1;31m# nt.barnes_hut()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Network' object has no attribute 'set_edge_minimization'"
     ]
    }
   ],
   "source": [
    "disegna_grafo(twitter_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6 Creazione grafo interattivo con pyvis\n",
    "\n",
    "def disegna_grafo(grafo):\n",
    "    nt = Network(\n",
    "        height =\"80%\",\n",
    "        width = \"80%\",\n",
    "        bgcolor=\"#222222\",\n",
    "        font_color=\"white\",\n",
    "        heading= grafo,\n",
    "        directed=True,\n",
    "    )\n",
    "    nt.show_buttons(filter_=None)\n",
    "    nt.from_nx(grafo)\n",
    "   # nt.barnes_hut()\n",
    "    nt.inherit_edge_colors(False)\n",
    "  # nt.set_edge_smooth(\"continuous\") #cambia formato di visualizzazione degli archi\n",
    "    neighbor_map = nt.get_adj_list()\n",
    "    \n",
    "    for node in nt.nodes:\n",
    "            node[\"value\"] = len(neighbor_map[node[\"id\"]])\n",
    "           # print(str(node[\"id\"])+\":\"+ str(node[\"value\"]))\n",
    "         \n",
    "    nt.show(\"grafo.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Main\n",
    "\n",
    "#Array usernames dei nodi principali\n",
    "usernames=[\"miccighel_\",\"mizzaro\",\"damiano10\",\"eglu81\",\"KevinRoitero\"]\n",
    "df_users= users_dfs(usernames)\n",
    "#Creazione del grafo\n",
    "twitter_graph=following_graph(df_users)\n",
    "#print(fg.nodes().data())\n",
    "twitter_graph.number_of_edges()\n",
    "#disegna_grafo(following_graph(df.loc[df['id'] == 1527461]))\n",
    "#disegna_grafo(fg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#7 Propriet√† del grafo\n",
    "undirected_twitter_graph= nx.to_undirected(twitter_graph)\n",
    "\n",
    "if nx.is_connected(undirected_twitter_graph):\n",
    "    print(\"Il grafo √® connesso.\")\n",
    "else:\n",
    "    print(\"Il grafo non √® connesso.\")\n",
    "    \n",
    "if nx.is_bipartite(undirected_twitter_graph):\n",
    "    print(\"Il grafo √® bipartito.\")\n",
    "else:\n",
    "    print(\"Il grafo non √® bipartito.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#8 Distanze sul grafo\n",
    "centro = nx.center(twitter_graph)\n",
    "print(centro)\n",
    "diametro = nx.diameter(twitter_graph)\n",
    "print(diametro)\n",
    "raggio = nx.radius(twitter_graph)\n",
    "print(raggio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#9 Misure di centralit√† sul grafo\n",
    "btw_centrality = nx.betweenness_centrality(twitter_graph)\n",
    "print(btw_centrality)\n",
    "cls_centrality = nx.closeness_centrality(twitter_graph)\n",
    "print(cls_centralitu)\n",
    "dg_centrality = nx.degree_centrality(twitter_graph)\n",
    "print(dg_centrality)\n",
    "\n",
    "in_centrality= nx.in_degree_centrality(twitter_graph)\n",
    "print(in_centrality)\n",
    "out_centrality= nx.out_degree_centrality(twitter_graph)\n",
    "print(out_centrality)\n",
    "#valori di centralit√†\n",
    "undirect_centralities=[btw_centrality,cls_centrality,dg_centrality]\n",
    "direct_centralities=[in_centrality,out_centrality]\n",
    "\n",
    "pagerank= nx.pagerank(twitter_graph)\n",
    "pagerank=sorted(pagerank.items(),key=lambda x:x[1],reverse=True)\n",
    "centralities= [btw_centrality,cls_centrality,dg_centrality,in_centrality,out_centrality]\n",
    "print(pagerank[:5])\n",
    "\n",
    "hits= nx.hits(twitter_graph)\n",
    "hits_hubs=hits[0]\n",
    "hits_hub= sorted(hits_hubs.items(),key=lambda x:x[1],reverse=True)\n",
    "print(hits_hub[:5])\n",
    "hits_authorities=hits[1]\n",
    "hits_authorities=sorted(hits_authorities.items(),key=lambda x:x[1],reverse=True)\n",
    "print(hits_authorities[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Sottografo del nodo KevinRoitero\n",
    "sub_graph_KevinRoitero = nx.ego_graph(twitter_graph, \"KevinRoitero\")\n",
    "disegna_grafo(sub_graph_KevinRoitero)\n",
    "clique.max_clique(sub_graph_KevinRoitero)\n",
    "print(nx.large_clique_size(sub_graph_KevinRoitero))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#11 copertua minima degli archi\n",
    "nx.min_edge_cover(twitter_graph)\n",
    "\n",
    "#12 Small-world-ness\n",
    "nx.omega(twitter_graph)\n",
    "nx.sigma(twitter_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#13 Correlazione di Pearson e di Kendall\n",
    "\n",
    "columns=[\"name\",\"value\"]\n",
    "centralita_df = pd.DataFrame(columns=columns)\n",
    "rows = [[\"btw_centrality\",btw_centrality],[\"cls_centrality\",cls_centrality],[\"dg_centrality\",dg_centrality],[\"in_centrality\",in_centrality],[\"out_centrality\",out_centrality]]\n",
    "#Creazione df contenente tipologia_misura : valore\n",
    "for row in rows:\n",
    "    centralita_df.loc[len(centralita_df)] = row\n",
    "#print(centralita_df)\n",
    "\n",
    "#Creazione df contenente  tipologia_misura_1 , tipologia_misura_2, valore_correlazione_1 , valore_correlazione_2\n",
    "columns=[\"name_1\",\"name_2\",\"pearson\", \"kendall\"]\n",
    "result= pd.DataFrame(columns=columns)\n",
    "\n",
    "for index, param_1 in centralita_df.iterrows():\n",
    "    for index, param_2 in centralita_df.iterrows():\n",
    "        if(param_1[\"name\"] != param_2[\"name\"]):\n",
    "            name_1= param_1[\"name\"]\n",
    "            name_2= param_2[\"name\"]\n",
    "            array_1= np.array(list(param_1[\"value\"].values()), dtype=float)\n",
    "            array_2= np.array(list(param_2[\"value\"].values()), dtype=float)\n",
    "            pearson= stats.pearsonr(array_1,array_2)\n",
    "            kendall= stats.kendalltau(array_1,array_2)\n",
    "            new_row = {\n",
    "            'name_1': name_1,\n",
    "            'name_2': name_2,\n",
    "            'pearson': pearson,\n",
    "            'kendall': kendall\n",
    "                }\n",
    "            result = result.append(new_row, ignore_index=True)\n",
    "\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
